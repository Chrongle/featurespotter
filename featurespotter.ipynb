{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definér transformations for billedet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((135, 135)),  # Tilpas til størrelsen på billeder, som mange CNN-modeller forventer\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definér CNN-arkitekturen\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128) # Efter at have max-poolet 3 gange, så ender vi med billeder der svarer til 5px * 5px\n",
    "        self.fc2 = nn.Linear(128, num_features)  # Outputlaget har antallet af features som output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 5 * 5)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opret en instans af CNN-modellen\n",
    "num_features = 12  # Antagelse: Der er 12 features eksklusive Pawpularity\n",
    "model = CNN(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1600, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indlæs den gemte model\n",
    "model_path = 'trained_model3.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # Sæt modellen i evalueringsmodus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion til at forudsige et enkelt billede\n",
    "def predict_single_image(model, image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)  # Anvend transformationer og tilføj batch-dimension\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        probabilities = torch.sigmoid(output)  # Anvend sigmoid for at få sandsynligheder\n",
    "    return probabilities.squeeze().cpu().numpy()  # Fjern batch-dimension og konverter til numpy-array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indsæt stien til dit billede\n",
    "image_path = 'pawpularity/train/cbc27493ddaca7127e8cee6705c3b75e.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Security percentage for Subject Focus: 92.28%\n",
      "Security percentage for Eyes: 94.65%\n",
      "Security percentage for Face: 94.20%\n",
      "Security percentage for Near: 94.07%\n",
      "Security percentage for Action: 4.39%\n",
      "Security percentage for Accessory: 47.45%\n",
      "Security percentage for Group: 37.45%\n",
      "Security percentage for Collage: 0.03%\n",
      "Security percentage for Human: 5.81%\n",
      "Security percentage for Occlusion: 1.20%\n",
      "Security percentage for Info: 2.32%\n",
      "Security percentage for Blur: 6.76%\n"
     ]
    }
   ],
   "source": [
    "# Få sandsynligheder for hver feature\n",
    "probabilities = predict_single_image(model, image_path)\n",
    "\n",
    "# Få sikkerhedsprocentsatser for hver feature\n",
    "feature_names = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n",
    "for i, feature_name in enumerate(feature_names):\n",
    "    print(f'Security percentage for {feature_name}: {probabilities[i] * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
